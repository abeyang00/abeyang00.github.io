---
title: Unsupervised Monocular Depth Estimation with Left-Right Consistency
subtitle: cvpr 2017
tags: [Deep Learning, Depth Estimation]
---

CVPR 2017년에 accept 된 논문으로 지금까지 supervised 방식으로 진행해왔던 depth estimation을 unsupervised learning으로 진행하고, 오히려 supervised쪽에서의 state-of-the-art 알고리즘들보다 압도적인 성능결과를 얻은 논문이다.

이 논문이 나오기 전까지 depth estimation은 supervised regression 문제로 해결하려고 했었다. 엄청 많은 양의 depth ground truth가 있다고 가정을 하고 regression network에서 나오는 output을 간단한 pixel-level loss (L1, L2, MSE, 등등...)를 minimize하는 형식으로 진행하였다.

Network를 다양한 환경에서 generalize 시킬려면 엄청나게 많은 ground truth 데이터가 필요하다. 다들 알다시피 depth ground truth는 구하기가 굉장히 어렵기 때문에 이 논문에서는 ground truth의 필요성을 아예 없애버린다. Ground truth를 사용하지 않고 binocular stereo 영상을 사용하여 unsupervised형식으로 depth estimation을 진행하게된다. 자세한 설명은 후에 또 하겠지만, 간단하게 말하면 Epipolar geometry constraints를 사용하여 disparity를 구하고, image reconstruction loss를 사용하여 network loss를 minimize시켜준다. 하지만 image reconstruction loss만을 사용하게 되면 결과로 나온 disparity가 blur하고 정확성이 떨어지기 때문에 stereo pair (left과 right 이미지)의 consistency를 고려해 loss에 추가해주게 된다.

이 논문에서 직접 말하는 contributions들은
1. left-right depth consistency를 고려해서 새로만든 loss function으로 network를 end-to-end 로 training을 할 수 있다는점
2. 다양한 training loss들과 비교했을때 이 논문의 loss function이 월등하다는 점 (뭐 이건 1번이랑 비슷한 맥락)
3. 자기들이 새로 취득한 데이터를 포함한 3가지 새로운 dataset에도 generalization이 잘된다는 점 
4. Inference시간은 35 milisecond 밖에 걸리지않아 real-time application에 적용할 수 있다는 점

좀더 자세히 알아보기 전에 epipolar geometry를 먼저 알아보자.

### Epipolar Geometry
Epipolar geometry는 stereo vision 즉 2-view 비전에서의 geometry라고 생각하면 된다. 다시말해, 동일한 사물 또는 장면에 대한 영상을 서로 다른 두 지점에서 획득 했을 때, 영상 A와 영상 B의 매칭쌍들 사이의 geometric relationship을 다루는 것이다. ![epipolar geometry](/img/vision/epipolar geometry.png)
위에 보이는 그림과 같이 3차원 공간상의 한 점 P가 영상 A에서는 p에 투영되고, 영상 B에서는 p^'에 투영된다고 가정해보자. 그렇다면 두 개의 카메라의 원점을 잇는 선과 이미지 평면이 만나는 점 e, e^'를 <span style="color:red"> epipole </span>이라고 부르고 epipole과 투영점을 잇는 직선 I, I^'를 <span style="color:red"> epiline </span>이라고 부른다. $$l^2$$ $l^2$

두 카메라 위치 사이의 

### Depth Estimation as Image Reconstruction








