---
title: Unsupervised Monocular Depth Estimation with Left-Right Consistency
subtitle: cvpr 2017
tags: [Deep Learning, Depth Estimation]
---

CVPR 2017년에 accept 된 논문으로 지금까지 supervised 방식으로 진행해왔던 depth estimation을 unsupervised learning으로 진행하고, 오히려 supervised쪽에서의 state-of-the-art 알고리즘들보다 압도적인 성능결과를 얻은 논문이다.

이 논문이 나오기 전까지 depth estimation은 supervised regression 문제로 해결하려고 했었다. 엄청 많은 양의 depth ground truth가 있다고 가정을 하고 regression network에서 나오는 output을 간단한 pixel-level loss (L1, L2, MSE, 등등...)를 minimize하는 형식으로 진행하였다.

Network를 다양한 환경에서 generalize 시킬려면 엄청나게 많은 ground truth 데이터가 필요하다. 다들 알다시피 depth ground truth는 구하기가 굉장히 어렵기 때문에 이 논문에서는 ground truth의 필요성을 아예 없애버린다. Ground truth를 사용하지 않고 binocular stereo 영상을 사용하여 unsupervised형식으로 depth estimation을 진행하게된다. 자세한 설명은 후에 또 하겠지만, 간단하게 말하면 Epipolar geometry constraints를 사용하여 disparity를 구하고, image reconstruction loss를 사용하여 network loss를 minimize시켜준다. 하지만 image reconstruction loss만을 사용하게 되면 결과로 나온 disparity가 blur하고 정확성이 떨어지기 때문에 stereo pair (left과 right 이미지)의 consistency를 고려해 loss에 추가해주게 된다.

이 논문에서 직접 말하는 contributions들은
1. left-right depth consistency를 고려해서 새로만든 loss function으로 network를 end-to-end 로 training을 할 수 있다는점
2. 다양한 training loss들과 비교했을때 이 논문의 loss function이 월등하다는 점 (뭐 이건 1번이랑 비슷한 맥락)
3. 자기들이 새로 취득한 데이터를 포함한 3가지 새로운 dataset에도 generalization이 잘된다는 점 
4. Inference시간은 35 milisecond 밖에 걸리지않아 real-time application에 적용할 수 있다는 점

좀더 자세히 알아보기 전에 epipolar geometry를 먼저 알아보자.

### Epipolar Geometry
Epipolar geometry는 stereo vision 즉 2-view 비전에서의 geometry라고 생각하면 된다. 다시말해, 동일한 사물 또는 장면에 대한 영상을 서로 다른 두 지점에서 획득 했을 때, 영상 A와 영상 B의 매칭쌍들 사이의 geometric relationship을 다루는 것이다. ![epipolar geometry](/img/vision/epipolar geometry.png)
위에 보이는 그림과 같이 3차원 공간상의 한 점 P가 영상 A에서는 $$p$$에 투영되고, 영상 B에서는 $$p^'$$에 투영된다고 가정해보자. 그렇다면 두 개의 카메라의 원점을 잇는 선과 이미지 평면이 만나는 점 $$e$$, $$e^'$$를 <span style="color:red"> epipole </span>이라고 부르고 epipole과 투영점을 잇는 직선 $$I$$, $$I^'$$를 <span style="color:red"> epiline </span>이라고 부른다. 

두 카메라 위치 사이의 geometric relationship [R|t] 알고있으면, A의 영상자료 $$p$$로부터 대응되는 B의 영상좌표 $$p^'$$를 유일하게 결정할 수는 없지만 $$p^'$$이 지나는 직선인 epiline $$l^'$$ 은 유일하게 결정할 수 있다. 이렇게 구해진 값과 Fundamental matrix와 essential matrix를 사용하면 $$p$$로 부터 $$p^'$$를 구할 수 있다. 자세한 정보는 [다크프로그래머](https://darkpgmr.tistory.com/83?category=460965) 를 통해 자세히 알아보면 된다.

이제 다시 본론으로 돌아와 논문을 자세히 알아보고자 한다.
### Depth Estimation as Image Reconstruction
이 네트워크의 목표는 카메라로부터 single image $$I$$가 들어왔을 때 depth map $$\hat{d}=f(I)$$를 구할 수 있는 mapping function $$f$$를 구하는 것이다. 앞서 말했듯 ground truth를 사용하지 않고 depth estimation을 image reconstruction 문제로 바꾼다. Calibration이 되어있는 stereo image pair ($$I^l,I^r)$$가 있다고 가정을 하면, 하나의 이미지 $$I^l$$로부터 $$I^r$$로 reconstruction할 수 있는 function을 학습시킬 수 있다면, 우리는 projection되는 scene에 대한 3차원 정보를 얻을 수 있다. 그래서 이렇게 구한 3차원 정보로 이 논문에서는 depth estimation을 진행한다. 

Training에서는 network가 depth를 바로 구하는 것이 아니라 먼저 correspondence field ($$d^r, d^^l$$)를 구한다. 왼쪽 이미지가 input 으로 들어갔을땐 right correspondence field $$d^r$$을, 오른쪽 이미지가 input으로 들어갔을땐 left correspondence field $$d^l$$을 구하게 된다. 이렇게 구해진 correspondence field로 왼쪽 이미지에서는 오른쪽 이미지를, 오른쪽 이미지에서는 왼쪽 이미지를 reconstruction 시킨다. $\tilde{$I^l}(d^r)$$








